---
layout: post

title: Emergence Part 3
subtitle: Creation of Intelligence

---

When the AI community started talking about the "sudden" capabilities of models above a certain size, I was appalled when I heard the claim "no one knows why". It felt obvious to me: you're skipping all the tasks that smaller nets could regress on. You're throwing these models into a sea of information with little to no basis to start with and essentially counting on them to randomly regress to a meaningful representation.
I believe if you started with simpler, more fundamental tasks akin to and exercising the fundamental senses, the regression would not occur near-randomly, but deterministically. This idea had been the basis for my work on what I'm now calling "structured learning" previously known as "curriculum learning" before I discovered that term is already taken; although, frustratingly it does not actually describe curriculum.
